%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[futureinternet,article,submit,pdftex,moreauthors]{Definitions/mdpi} 

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% For posting an early version of this manuscript as a preprint, you may use "preprints" as the journal. Changing "submit" to "accept" before posting will remove line numbers.

%---------
% article
%---------

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. Remove "pdftex" for (1) compiling with LaTeX & dvi2pdf (if eps figures are used) or for (2) compiling with XeLaTeX.

%=================================================================
% MDPI internal commands - do not modify
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2024}
\copyrightyear{2024}
%\externaleditor{Academic Editor: Firstname Lastname}
\datereceived{ } 
\daterevised{ } % Comment out if no revised date
\dateaccepted{ } 
\datepublished{ } 
%\datecorrected{} % For corrected papers: "Corrected: XXX" date in the original paper.
%\dateretracted{} % For corrected papers: "Retracted: XXX" date in the original paper.
\hreflink{https://doi.org/} % If needed use \linebreak
%\doinum{}
%\pdfoutput=1 % Uncommented for upload to arXiv.org
%\CorrStatement{yes}  % For updates


%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, float, amsmath, amssymb, lineno, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, colortbl, soul, multirow, microtype, tikz, totcount, changepage, attrib, upgreek, array, tabularx, pbox, ragged2e, tocloft, marginnote, marginfix, enotez, amsthm, natbib, hyperref, cleveref, scrextend, url, geometry, newfloat, caption, draftwatermark, seqsplit
% cleveref: load \crefname definitions after \begin{document}

%PLACE TO ADD COMMANDS
\usepackage{lipsum}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}

%=================================================================
% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{A Lightweight AI-based  Approach For Drone Jamming Detection}

% MDPI internal command: Title for citation in the left column
\TitleCitation{A Lightweight AI-based  Approach For Drone Jamming Detection}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0009-0001-6239-0572} % Add \orcidA{} behind the author's name
\newcommand{\orcidauthorB}{0000-0002-0267-4733} % Add \orcidB{} behind the author's name
\newcommand{\orcidauthorC}{0000-0001-6271-7988}

% Authors, for the paper (add full first names)
\Author{Sergio Cibecchini*\orcidA{}, Francesco Chiti $^{1}$\orcidB{} and Laura Pierucci$^{1}$\orcidC{}}

%\longauthorlist{yes}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Sergio Cibecchini, Francesco Chiti and Laura Pierucci}

% MDPI internal command: Authors, for citation in the left column
\AuthorCitation{Cibecchini, S.; Chiti, F.; Pierucci, L.}
% If this is a Chicago style journal: Lastname, Firstname, Firstname Lastname, and Firstname Lastname.

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Associate Professor at Dipartimento di Ingegneria dell'Informazione, Universit√† degli Studi di Firenze, Firenze, Italy; francesco.chiti@unifi.it, laura.pierucci@unifi.it
}


% Contact information of the corresponding author
\corres{Correspondence: sergio.cibecchini@gmail.com}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation.}  % Current address should not be the same as any items in the Affiliation section.
%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{The future integration of drones in 6G networks will significantly enhance their capabilities, enabling a wide range of new applications based on autonomous operation. However, drone networks are particularly vulnerable to Jamming attacks, a type of Availability attack that can disrupt network operation and hinder drone functionality. In this paper, we propose an unsupervised machine learning approach for the detection of constant and periodic jamming attacks, using the Isolation Forest algorithm. The base model has been tuned to best fit the proposed scenario, but faced challenges related to environmental noise in the dataset. To address this, we introduced a Majority Rule module which significantly reduced the number of false positives, achieving high accuracy and precision. Our approach outperforms the standard Isolation Forest model in the detection of both constant and periodic jamming attacks, while still correctly identifying normal traffic. Finally, we discuss the potential integration of the proposed solution in 6G-enabled drone networks, as a lightweight edge-based solution for enhancing security against jamming attacks. }

% Keywords
\keyword{Jamming attacks, 6G Drone Networks, Isolation Forest, Machine Learning, Edge AI, IoT Security} 

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{section}{-1} %% Remove this when starting to work on the template.
\section{Introduction}

The shift from 4G to 5G has been a generational leap has revolutionized connectivity. 
Despite 5G being still in its early adoption rate at the time of writing \cite{5GStatisticsTaylor}, the research community is already working on the next generation of wireless communication technologies, 6G. 

6G technology is expected to enable a wide variety of new use cases, thanks to the increases in both data rates and latency, but this in turn 
will also bring forth new security challenges specific to those applications. 

One of the main differences between 5G and 6G technology will be a much deeper integration with AI. While Software Defined Networks (SDN) have played a key role in improving the efficiency and security 
of 5G networks, 6G is expected to take this a step further, by designing the networks to be integrated with artificial intelligence from the ground up. This is what the authors of \cite{6GRoadmapLetaief} define as 
the shift from \textit{Softwarization} to \textit{Intelligentization}.

AI integration in 6G networks will greatly strengthen the security of the network against potential threats. 
By leveraging Diagnostic Analytics, a collection of insights into the status of the networks, security teams 
will be able to train specific AI models to detect and respond to security threats in real-time.

In this paper we will focus on a specific aspect of the security of 6G networks, namely we will provide a lightweight edge-based machine learning approach 
for the detection of jamming attacks in networks of drones.

We conceptualize a scenario where a drone is subject to constant and periodic jamming and has to rely on an internal AI model to detect the attack and apply the appropriate countermeasures. IoT devices in 6G networks
will be equipped with AI-specific chips that will allow them to run AI models directly on the edge, without the need to offload computation to a central server. This is especially useful in the case of jamming attacks, where the communication between the device and the server is disrupted.

Our solution is designed to run on a resource constrained IoT device like a drone and to be lightweight, both in terms of memory usage and computational power.
Despite the low resources requirements, the proposed approach is able to detect both constant and periodic jamming attacks with a high degree of accuracy, as well as correctly classify normal traffic. 

The paper is divided in 5 sections: 
\begin{enumerate}
	\item \textbf{Topic overview:} General overview of the benefits of drone integration in 6G networks, analysis of jamming attacks: types, mitigation and detection. Discussion of the advantages provided by an edge AI approach for jamming detection. 
	\item \textbf{System Model:} Description of the analyzed scenario, along with the dataset, algorithms, and evaluation metrics chosen for the tests.
	\item \textbf{Model Performance:} Explanation of the testing methodology, including model tuning, testing phases, and a presentation of the obtained results.
	\item \textbf{Discussion:} Analysis of the results from the previous section, emphasizing the advantages of the proposed approach.
	\item \textbf{Conclusions:} Overview of how the proposed solution applies to real-world scenarios, with a discussion on potential future research directions.
\end{enumerate}

\section{Related Works}

Detection of jamming attacks in wireless networks has been a topic of interest for the research community for many years. A wide variety of approaches have been proposed for different types of networks, with most of the work focusing on the detection of jamming attacks in Vehicular Ad-Hoc Networks (VANETs)\cite{VANETsAI-Lyamin}.

This work build upon the research done in \cite{JammingDetectionIoT-Hussain}, where the authors analyze a machine learning based approach for the detection of jamming attacks. 
The authors propose the use of Convolutional Neural Networks (CNNs) to detect jamming attacks in a IoT drone scenario. The authors show that the CNN model is able to achieve a high detection rate against constant jamming attacks, but it 
struggles in the classification of periodic jamming and normal traffic. 

The authors of \cite{GPSSpoofingDetection-Zuo} propose an Isolation Forest based approach for the detection of GPS spoofing attacks, while the authors of \cite{HybridJammingDetection-Hong} successfully applied a combination of decision trees and Isolation forest to classify 
and detect jamming attacks in a mobile scenario. 

Our solution also leverages the Isolation Forest algorithm for jamming detection in the scenario of a 6G drone network, testing the model against the dataset created by \cite{JammingDetectionIoT-Hussain}.
We propose a lightweight approach that integrates a specifically tuned Isolation Forest with a Majority Rule module to reduce the number of false positives and improve the resistance of the model to environmental noise.
Our approach reached a high detection rate against both constant and periodic jamming attacks, while also being able to classify normal traffic with a high degree of accuracy. We also detailed the tuning of the model's hyperparameters to fit our specific scenario and compared it 
against the default model. In the tuning phase, the resource constrained nature of the scenario was a key deciding factor in the selection of the more appropriate hyperparameters.

\section{Topic Overview}

\subsection{6G Drone Networks}

Drones, also known as Unmanned Aerial Vehicles (UAVs) are defined as \textit{all aircraft designed to fly
without a pilot on board} \cite{DronesEC}. This technology has experienced rapid growth in recent years and is expected to 
keep growing in both the consumer sector as well as the commercial and military sectors \cite{DronesStatisticsLaricchia}.

In technical report 22.886 \cite{5GV2XSultan} 3GPP identifies some of the envisioned use cases for 5G V2X (Vehicle-to-
Everything) communication services. Among these use cases, advanced and remote driving, vehicle platooning and extended situational awareness are identified as some of the main benefits
of V2V communication. All these capabilities can be leveraged by a 6G drone network to achieve fast and reliable drone-to-drone communication, that, with the integration of artificial intelligence, 
would allow the drones to act autonomously in a coordinated manner. 

This would prove useful in a variety of fields: from autonomous irrigation as well as soil and crop health assessment in agriculture, 
delivery of life saving supplies and identification of survivors in disaster response, in the delivery sector as a more eco friendly alternative to traditional 
delivery options and possibly in the mobility sector as a complement to traditional taxis and public transportation \cite{DroneCommHassija}. 

In the military sector, the effectiveness of drones is widely recognized, both for high and low end models and are being used in a variety of roles, from more passive roles like surveillance and intelligence gathering, to more active roles like
delivery of explosives and targeted strikes. 

Security against Jamming attacks is crucial in all these applications, especially in a safety critical environment. 

\subsection{Understanding Jamming Attacks}

Jamming attacks are a type of Denial of Service (DoS) attack that aims at disrupting the physical communication between two or more devices. 
This is achieved by transmitting a signal on the same frequency as the one used by the devices to communicate. If the jamming signal power level is high enough, 
it is able to overwhelm the legitimate signal, effectively blocking the communication between the devices \cite{DroneCommHassija}. 
Since the ability to communicate is affected, Jamming attacks falls under the umbrella of attacks that target the \textit{Availability} of the service in the CIA triad \cite{DataIntegrityCawthra}. 
Jamming attacks can be classified into 5 main categories, based on the attack pattern of the jammer: 

\begin{itemize}
    \item \textbf{Constant Jamming:} The jammer continuously transmits a strong signal on the same frequency used by the devices it wants to disrupt to communicate. 
    \item \textbf{Periodic Jamming:} The jammer transmits a strong signal for a certain period of time \(t_a\), then stops transmitting for another period of time \(t_b\). This cycle is repeated until the attack is stopped.
    \item \textbf{Random Jamming:} In random jamming, the jammer is active at random intervals, jamming each transmitted packet with a probability 
    \(p\) based on a random pattern\cite{VANETsAI-Lyamin}. 
    \item \textbf{Reactive Jamming:} A reactive jammer starts transmitting its jamming signal only when it senses energy in the communication channel, 
    indicating that a legitimate transmission is taking place. This type of jamming attack is more power efficient compared to other 
    attack patterns, as it only transmits its signal when it know that it can actually disrupt the communication\cite{MLMisbehavior5GBoualouache}.
    \item \textbf{Smart Jamming:} A smart jammer is a more sophisticated type of jammer that is able to adapt its jamming signal to 
    maximize the disruption of the communication between the devices. Smart jammers employ a traffic analysis module, meaning they are able to modify their attack pattern based on the 
    transmission specifics of the devices they are targeting and adapt to changes in the communication channel\cite{AntiJammingV2V-Feng}.
\end{itemize}


\subsection{Jamming attacks against drone networks}\label{JammingDroneNetworks}

Jamming attacks are particularly effective against drone networks, as drones usually rely on external input to navigate and operate correctly.
If a jammer were able to completely block the communication between the drone and the base station, the drone would be left without any indication on how to behave and would need to activate an internal failsafe mechanism. 
This usually comes in the form of either a return to base procedure, a hover in place procedure or a land in place procedure.
All of these approaches leave the drone in a vulnerable position, as a bad actor could potentially capture the drone and use it for malicious purposes.
This is especially true when jamming attacks are used in combination with other types of attacks, such as spoofing attacks. 

One real world example is the capture of an American drone by Iran in 2011. 
In December 2011 a Lockheed Martin \textit{RQ-170} Sentinel drone operated by the United States Air Force was flying over Iran when its operators lost control of the vehicle. The US government initially claimed that the drone had crashed due to a technical malfunction, but later reports revealed that the drone had been captured by the Iranian military. 
Iranian electronic warfare specialists claimed to have brought it down using a Jamming attack, that forced the drone into a return to base procedure, in combination with a  GPS spoofing attack, that made the drone land into a designated area \cite{RQ170DroneOwano}. 
After successfully capturing the drone, the Iranian government managed to reverse-engineer the drone and produce a working replica, which was then used in their military operations \cite{IranianUAVGross}.

\subsection{Centralized vs Edge approach for Jamming detection}

When presenting a Machine Learning (ML) based approach in an IoT setting, the question of where the AI model should be placed often arises. By their nature, IoT devices, and in turn drones, are usually resource constrained, 
both in terms of computational power but also in terms of internal storage and battery capacity \cite{6GSecurity-Chorti}. This means that complex AI models and algorithms are usually not feasible to be run on the device itself. A centralized approach 
offloads the computational burden to a central server, that returns the results of the AI model to the device. While this scheme might be favorable in some cases, in a real-time situation such as a jamming attack, the latency introduced by the
communication with the server means less time to react to the attack. Also, as jamming attacks degrade or sometimes completely block the communication between the device and the base station, a centralized approach might not be feasible in this case.
A collaborative edge approach would suffer from the same problems, as there is a high likelihood that the communication between the devices would be disrupted by the attack. 
Implementing a lightweight on-device edge approach, on the other hand, while not as precise as a centralized approach, would provide real-time results and would be able to operate even when the communication is disrupted, as in a jamming situation. 


\subsection{Detection and Mitigation of Jamming Attacks}\label{sec:DetectionMitigation}

The state of the art approaches for jamming detection involve monitoring of the communication link and the analysis of metrics such as the Signal to Noise Ration (SNR), the Received Signal Strength (RSS) and the Packet Delivery Ratio (PDR) \cite{JammingDetection-Sciancalepore}. The simplest approach when 
developing a method to detect jamming attacks is to set a static threshold for these metrics and trigger an alarm when the threshold is crossed. While this approach is easy to implement and might be effective in some cases, it is not able to adapt to changes in the communication channel and might be prone to false positives.
Implementing a ML based approach for jamming detection would allow the system to adapt to the changes in the communication channel and would be able to provide a more accurate detection of jamming attacks \cite{VANETsAI-Lyamin}. This is especially useful in mobile scenarios like 
drone networks, where the environment is constantly changing and the signal strength can vary greatly. 

Once an attack is successfully detected, state of the art jamming mitigation techniques, like Direct Sequence Spread Spectrum (DSSS), Frequency Hopping (FHSS) and advanced signal processing techniques can be put in place to mitigate the 
effects of the attack. 

The use of an AI model for jamming detection is particularly suitable for a 6G network, as the improved sensing capabilities would allow the model to train on a wide variety of diagnostic data, improving the detection rate and accuracy of the model. 
Furthermore, as the network is expected to be integrated with AI from the ground up, its likely that in the future drones will be equipped with AI-specific chips for a more efficient execution of AI models.

\section{System Model}

\subsection{Scenario Definition and Attacker Classification}

In the proposed scenario we have a flying drone that is subject to a jamming attack. The drone communicates with a ground station and periodically samples the Received Signal Strength (RSS) of the signal it receives. 
The drone implements a simple unsupervised machine learning algorithm module, trained on nominal traffic RSS values. The module takes the sampled RSS values and classifies them as either normal or anomalous, making the drone able to determine wether or not a jamming attack is taking place. 


We assume that a jammer is deployed in the network and that it starts a jamming attack at a certain instant by transmitting a high power signal on the same frequency as the one used by the drone to communicate with the ground station.
We assume that the jammer is able to completely block the communication between the drone and the ground station, meaning the drone has to rely on its internal classification algorithm to determine if a jamming attack is taking place and react accordingly.
We assume that the jammer type is unknown to the drone. 

Figure \ref{fig:CombinedJammingscenariosDiagram} shows a diagram of the proposed scenario. 

\begin{figure}[H]
	\includegraphics[width=10.5 cm]{img/CombinedJammingscenariosDiagram.jpg}
	\caption{Proposed jamming scenario. The Drone communicates with the 6G base station and receives information about how to behave. The fixed jammer \textbf{(1)} and the mobile jammer \textbf{(2)} target the communication between the drone and the base station. The drone has an internal classification module that is able to detect jamming attacks.}
	\label{fig:CombinedJammingscenariosDiagram}
	\end{figure}   
	\unskip


In our scenario, the drone will be subject to two types of jamming attacks, a constant jamming attack and a periodic jamming attack.
These types of attacks can be attributed to different types of jammers. The constant jamming attack could be caused by a ground jammer, as maintaining a constant jamming signal requires a large power source, while 
the periodic jamming attack could be caused by a mobile jammer, for example a drone, as drones are usually battery powered and can only jam for a limited amount of time. 
Employing a periodic jamming attack could help the malicious drone preserve energy and reduce the chances of being detected.

Table \ref{tab:attacker_classification} shows the attacker classification in the proposed scenario \cite{MLMisbehavior5GBoualouache}: 

\begin{table}[H]
	\caption{Attacker classification details.\label{tab:attacker_classification}}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{Classification} & \textbf{Description} \\
	\midrule
	Active   & The attacker is actively trying to disrupt network operation by transmitting a jamming signal\\
	External & The attack takes place at level 1 of the OSI model, meaning that the attacker is not part of the network\\
	Local    & The attack is local, as it is targeted at a specific drone or drone cluster and not at the entire network\\
	Malicious & Jamming attacks are considered malicious as their main goal is to disrupt correct network operation\\
	\bottomrule
\end{tabularx}
\end{table}

\subsection{Dataset Choice}\label{sec:DatasetChoice}

As 6G network traffic is not yet widely available, we chose an open-source dataset \cite{JammingDetectionIoT-Hussain} that analyses the RSS values 
received by a Raspberry Pi 3 that is subject to periodic and constant jamming attacks. 

The dataset in \cite{JammingDetectionIoT-Hussain} was created using a software-defined radio (SDR) connected to a laptop that was programmed to transmit a jamming signal using the 
open source software \textit{GNU Radio}. A second SDR radio was connected to a Raspberry Pi 3, designated to receive the jamming signal. The jamming radio operates at a frequency of $2.412 GHz$ with a Bandwidth of $40MHz$, while the Raspberry Pi 3 was programmed to sample the RSS values with a frequency of $32K$ samples per second. 

The dataset contains 3 different \textit{.txt} files that store the RSS values sampled by the Raspberry Pi 3. The first file contains the RSS values sampled during a constant jamming attack, the second file contains the RSS values sampled during a periodic jamming attack and the third file contains the RSS values sampled during normal network operation.
The samples are stored in a single column, with each row representing a single sampled RSS value, represented using the \textit{dBm (decibel-milliwatts)} unit of measurement. 

Figures \ref{fig:ConstantJammingSignal} and \ref{fig:PeriodicJammingSignal} show respectively plots of the RSS values sampled during a constant jamming attack and a periodic jamming attack, while Figure \ref{fig:normalSignal} shows the RSS values sampled during normal network operation.

\begin{figure}[H]
	\begin{adjustwidth}{-\extralength}{0cm}
	\centering
	\includegraphics[width=21cm]{img/ConstantJammingSignal.png}
	\end{adjustwidth}
	\caption{Constant jamming attack RSS values}\label{fig:ConstantJammingSignal}
\end{figure}  
\unskip
\begin{figure}[H]
	\begin{adjustwidth}{-\extralength}{0cm}
	\centering
	\includegraphics[width=21cm]{img/PeriodicJammingSignal.png}
	\end{adjustwidth}
	\caption{Periodic jamming attack RSS values}\label{fig:PeriodicJammingSignal}
\end{figure}  
\unskip

\begin{figure} [H]
	\begin{adjustwidth}{-\extralength}{0cm}
	\centering
	\includegraphics[width=21cm]{img/NormalSignal.png}
	\end{adjustwidth}
	\caption{Normal network operation RSS values}\label{fig:normalSignal}
\end{figure}
\unskip

\subsection {Detection Algorithm}

When choosing the algorithm for the classification module, we first had to define the requirements that the algorithm is required to meet. The algorithm has to be able to classify anomalous samples with a high detection rate (Recall), while at the same time 
being lightweight enough in terms of memory usage and computational power to be run on a resource constrained device like a drone. The training phase should also be fast, as this would allow the drone to quickly determine the normal transmission RSS values in a constantly changing environment. A periodical redefinition of normal RSS values would 
limit the number of false positives caused by the drone mobility. 
The model should be also required a small amount of storage to run effectively, as drones are usually very limited in internal memory. 

The algorithm that best fit these requirements was the \textit{Isolation Forest} algorithm \cite{IsolationForestLiu}. The Isolation Forest (IF) algorithm is a state-of-the-art unsupervised machine learning algorithm for anomaly detection, introduced by Liu et al. in 2008. 
Unlike traditional anomaly detection algorithms, which require the definition of a normal class, IF is able to detect anomalies without explicitly defining its characteristics.
This is achieved by leveraging the properties of anomalies themselves, i.e being rare and separated from the majority of the data points. 

The algorithm works by building a forest of isolation trees. Each tree is built by randomly selecting one of the features and then splitting the data points based on a value randomly selected between the minimum and maximum value of the feature. This partitions the data into the 
left and right branches of the tree. The process is repeated recursively until all the data points are isolated, as shown in Figure \ref{fig:IsolationForest}. The height of a node, meaning the number of splits required to isolate it, is used to determine the anomaly score of the data point. The greater the number of splits, the more likely the data point is to be an anomaly.
IF is an \textit{ensamble} algorithm, meaning that the final anomaly score is calculated by averaging the anomaly scores of all the trees in the forest. More trees mean more accuracy but also more computational power required.

\begin{figure}[H]
	\includegraphics[width=6 cm]{img/IsolationForest.jpg}
	\caption{Isolation forest in action. The anomaly \textbf{x0} is isolated in less splits compared to the normal datapoint \textbf{x1}\cite{IsolationForestLiu}.}
	\label{fig:IsolationForest}
\end{figure}   
\unskip

The chosen implementation for IF is the one provided by the \textit{Scikit-learn} library \cite{IsolationForestScikitLearn} for Python 3. 

\subsection{Evaluation Metrics}\label{EvaluationMetrics}

The performance of the model was evaluated using the state-of-the-art evaluation metrics for ML classification algorithms. The metrics are all based on the number of true positives, false positives, true negatives and false negatives.
The chosen evaluation metrics are the following: 

\begin{itemize}
	\item \textbf{Accuracy:} the ratio of correctly classified data points to the total number of data points.
	\begin{equation}
		\label{eq:accuracy}
	  Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
	\end{equation}
	\item \textbf{Precision:} the ratio of correctly classified anomalies to the total number of data points classified as anomalies.
	\begin{equation}
		\label{eq:precision}
	  Precision = \frac{TP}{TP + FP}
	\end{equation}
	\item \textbf{Recall:} the ratio of correctly classified anomalies to the total number of anomalies.
	\begin{equation}
		\label{eq:recall}
	  Recall = \frac{TP}{TP + FN}
	\end{equation}
	\item \textbf{F1 Score:} the harmonic mean of the precision and recall.
	\begin{equation}
		\label{eq:f1}
	  F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
	\end{equation}
\end{itemize}

The combination of these metrics gives us an important insight into the performance of the model. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Performance }

\subsection{Parameters Tuning Phase}

The first phase in our testing methodology was the tuning of the model's hyperparameters. The tuning was performed by making the parameters vary between a minimum and a maximum value, evaluating the impact on the performance metrics (depicted in Section \ref{EvaluationMetrics}) and then choosing the best values.
From the parameters available in the \textit{Scikit-learn} implementation of the Isolation Forest, we decided to tune were the following: 

\begin{itemize}
	\item \textbf{n\_estimators:} the number of base estimators in the ensamble, i.e the number of isolation trees used to compute the anomaly score of each datapoint. 
	\item \textbf{max\_samples:} the max number of samples to draw from the dataset to train each tree.
	\item \textbf{contamination:} the amount of outliers present in the training dataset.  
\end{itemize}

During the tuning phase, the untested hyperparameters were set to the default values of the \textit{Scikit-learn} implementation of the Isolation Forest (table \ref{tab:isolation_forest_parameters}).

\begin{table}[H]
	\caption{Scikit-Learn Isolation Forest hyperparameters default values.\label{tab:isolation_forest_parameters}}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{Parameter} & \textbf{Default Value} \\
	\midrule
	n\_estimators & 100 \\
	max\_samples & 'auto' \\
	contamination & 0.1 \\
	\bottomrule
	\end{tabularx}
\end{table}

The model was evaluated using as input normal traffic samples concatenated with jamming attack samples (see code snippet \ref{alg:dataset_concatenation}). 
This was done to simulate a real-world scenario where the model has to be able to correctly classify anomalous samples but also reduce the number of false positives during normal operation. 

\begin{algorithm}
	\caption{Test input definition}\label{alg:dataset_concatenation}
	\begin{algorithmic}[1]
	\State normalTraffic $\gets$ ReadAndParseFile(NORMAL\_TRAFFIC\_FILE, normal\_traffic\_size)
	\State jamming $\gets$ ReadAndParseFile(JAMMING\_FILE, jamming\_size)

	\State testInput $\gets$ Concatenate(normalTraffic, jamming)
	\end{algorithmic}
\end{algorithm}

The values whe chose for \textit{normal\_traffic\_size} and \textit{jamming\_size} are shown in Table \ref{tab:dataset_sizes}. 

\begin{table}[H]
	\caption{Dataset sizes used for the tuning and testing phases.}\label{tab:dataset_sizes}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{Dataset} & \textbf{Size} \\
	\midrule
	normal\_traffic\_size & 20000 \\
	jamming\_size & 2000 \\
	\bottomrule
\end{tabularx}
\end{table}

The dataset is intentionally unbalanced between normal data points and anomalous points, as jamming attacks are usually rare events compared to normal network operation. 

In Figure \ref{fig:InputSignal} we can see a representation of the input signal in the case of a constant jamming attack. The proposed results, unless otherwise specified, are based on the input signal shown in Figure \ref{fig:InputSignal}, which employs constant jamming. Periodic jamming always showed comparable trends as constant jamming in all the performed tests.


\begin{figure}[H]
    \begin{adjustwidth}{-\extralength}{0cm}
        \centering
        \includegraphics[width=21cm]{img/InputSignal.png}
    \end{adjustwidth}
    \caption{Input signal in the case of Constant Jamming. The normal traffic signal is concatenated with the jamming signal.}
    \label{fig:InputSignal}
\end{figure}


\subsubsection{n\_estimators tuning}

The first parameter that we decided to tune was the \textit{n\_estimators} parameter. The tuning values are shown in Table \ref{tab:n_estimators_tuning}.

\begin{table}[H]
	\caption{n\_estimators tuning values.}\label{tab:n_estimators_tuning}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{n\_estimators} & \textbf{Values} \\
	\midrule
	Minimum & 1 \\
	Maximum & 50 \\
	Step & 1 \\
	\bottomrule
\end{tabularx}
\end{table}

The effect on the evaluation metrics of the model is shown in Figure \ref{fig:n_estimators_tuning}.

\begin{figure}[H]
	\includegraphics[width=10.5cm]{img/nEstimatorsTuning.png}
	\caption{n\_estimators tuning results.}\label{fig:n_estimators_tuning}
\end{figure}
\unskip

As we can see from the graph, performance increases as the estimators increase, while converging to a stable value. 
In graphs \ref{fig:n_estimators_training_time} and \ref{fig:n_estimators_classification_time} is shown that the time required both for training and classification increases linearly with the number of estimators.
This means that choosing an appropriate number of estimators is crucial, as it can greatly affect the model performance. 

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/nEstimatorsTrainingTime.png}
        \caption{n\_estimators training time.}
        \label{fig:n_estimators_training_time}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/nEstimatorsClassificationTime.png}
        \caption{n\_estimators classification time.}
        \label{fig:n_estimators_classification_time}
    \end{subfigure}
    \caption{Comparison of n\_estimators training and classification times.}
    \label{fig:estimators_time_comparison}
\end{figure}


We accordingly selected \textbf{n\_estimators = 15}, as it provided a good balance between model performance and computational resources required.
The model metrics keep slowly improving until $45$ estimators, but the performance increase is minimal, making it not worth such a large increase in training and classification time, especially considering the resource-constrained nature of the scenario under consideration. 

\subsubsection{max\_samples tuning}

The second parameter that we decided to tune was the \textit{max\_samples} parameter. The tuning values are shown in Table \ref{tab:max_samples_tuning}.

\begin{table}[H]
	\caption{max\_samples tuning values.}\label{tab:max_samples_tuning}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{max\_samples} & \textbf{Values} \\
	\midrule
	Minimum & 1 \\
	Maximum & 100 \\
	Step & 1 \\
	\bottomrule
\end{tabularx}
\end{table}

From Figure \ref{fig:max_samples_tuning} we can see that the model performance is not greatly affected by the \textit{max\_samples} parameter. This is most likely due to the great difference in RSS values between the normal traffic samples and the jamming attack samples, meaning the model can develop the ability to correctly classify the input even with a limited training set.

\begin{figure}[H]
	\includegraphics[width=10.5cm]{img/maxSamplesTuning.png}
	\caption{max\_samples tuning results.}\label{fig:max_samples_tuning}
\end{figure}
\unskip

However, as the model has to build bigger trees, the \textit{max\_samples} parameters has considerable influence on the training and classification time, as shown in Figure \ref{fig:max_samples_time_comparison}.
Given the minimal performance differences but the impact on the time metrics, we chose the value of \textbf{max\_samples = 10}. 

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/maxSamplesTrainingTime.png}
		\caption{max\_samples training time.}
		\label{fig:max_samples_training_time}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/maxSamplesClassificationTime.png}
		\caption{max\_samples classification time.}
		\label{fig:max_samples_classification_time}
	\end{subfigure}
	\caption{Comparison of max\_samples training and classification times.}
	\label{fig:max_samples_time_comparison}
\end{figure}

\subsubsection{contamination tuning}

The final parameter we focused on is the \textit{contamination} parameter. The tuning values are shown in Table \ref{tab:contamination_tuning}.

\begin{table}[H]
	\caption{contamination tuning values.}\label{tab:contamination_tuning}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{contamination} & \textbf{Values} \\
	\midrule
	Minimum & 0.01 \\
	Maximum & 0.5 \\
	Step & 0.01 \\
	\bottomrule
	\end{tabularx}
\end{table}

The contamination parameter is by far the one that has the most impact on the model performance, as shown in Figure \ref{fig:contamination_tuning}.
Since recall is the metric that we want to prioritize as it highlights the number of detections, we chose the value of \textbf{contamination = 0.09}.

\begin{figure}[H]
	\includegraphics[width=10.5cm]{img/contaminationTuning.png}
	\caption{contamination tuning results.}\label{fig:contamination_tuning}
\end{figure}
\unskip

Our testing showed that, as expected, tuning of the contamination parameter has minimal impact on the training and classification time. 

\subsection{Model Testing Phase}

\subsubsection{Standard model testing}\label{sec:standardModelTesting}

After the tuning phase, we tested the model using the best performing hyperparameters, detailed in Table \ref{tab:best_hyperparameters} and compared against the default parameters. 


\begin{table}[H]
	\caption{Tuned hyperparameters and default values} \label{tab:best_hyperparameters}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CCC}
	\toprule
	\textbf{Parameter} & \textbf{Tuned Value} & \textbf{Default Value} \\
	\midrule
	n\_estimators & 15 & 100 \\
	max\_samples & 10 & 'auto' \\
	contamination & 0.09 & 0.1 \\
	\bottomrule
	\end{tabularx}
\end{table}



The model was tested against the input signal shown in Figure \ref{fig:InputSignal}. In Figure \ref{fig:standardIsolationResults} we can see the results of the model classification of the input signal with the tuned hyperparameters. 

\begin{figure}[H]
	\begin{adjustwidth}{-\extralength}{0cm}
	\centering
	\includegraphics[width=21cm]{img/StandardIsolationForestClassification.png}
	\end{adjustwidth}
	\caption{Classification results from the tuned Isolation Forest model}\label{fig:standardIsolationResults}
\end{figure}  

Table \ref{tab:confusionMatrix} and \ref{tab:performanceMetrics} show a comparison between the model performance with the tuned and the default hyperparameters.

\begin{table}[H]
    \caption{Confusion Matrix Components Comparison.}\label{tab:confusionMatrix}
    \newcolumntype{C}{>{\centering\arraybackslash}X}
    \begin{tabularx}{\textwidth}{CCC}
    \toprule
    \textbf{Metric} & \textbf{Tuned Isolation Forest} & \textbf{Default Isolation Forest} \\
    \midrule
    \textbf{TP} & 1997 & 2000 \\
    \textbf{FP} & 1565 & 1993 \\
    \textbf{TN} & 18435 & 18007 \\
    \textbf{FN} & 3 & 0 \\
    \bottomrule
    \end{tabularx}
\end{table}

Figures \ref{fig:ConfusionMatrixStandardIF} and \ref{fig:ConfusionMatrixTunedIF} show, respectively, the confusion matrix for the default and the tuned Isolation Forest model.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/ConfusionMatrixStandardIF.png}
		\caption{}
		\label{fig:ConfusionMatrixStandardIF}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/ConfusionMatrixTunedIF.png}
		\caption{}
		\label{fig:ConfusionMatrixTunedIF}
	\end{subfigure}
	\caption{Confusion Matrix for the default Isolation Forest model \textbf{(a)} and the tuned Isolation Forest model \textbf{(b)}.}
	\label{fig:ConfusionMatrixStandardTunedIF}
\end{figure}


\begin{table}[H]
    \caption{Performance Metrics Comparison.}\label{tab:performanceMetrics}
    \newcolumntype{C}{>{\centering\arraybackslash}X}
    \begin{tabularx}{\textwidth}{CCC}
    \toprule
    \textbf{Metric} & \textbf{Tuned Isolation Forest} & \textbf{Default Isolation Forest} \\
    \midrule
    \textbf{Accuracy} & 0.929 & 0.909 \\
    \textbf{Precision} & 0.561 & 0.501 \\
    \textbf{Recall} & 0.999 & 1.000 \\
    \textbf{F1 Score} & 0.718 & 0.667 \\
    \bottomrule
    \end{tabularx}
\end{table}


The tuning phase proved effective in improving the model's performance compared to the default hyperparameters,with an increase of $2.20\%$ in accuracy, $11.98\%$ in precision, and $7.64\%$ in the F1 score, while maintaining a nearly identical recall ($0.1\%$ drop). However, despite reaching a very high Recall score in both scenarios, the model is still too prone to false positives, as indicated by the value of the Precision metric. 
This is most likely due to the nature of the normal traffic signal. As we see from Figure \ref{fig:standardIsolationResults}, many of the normal traffic samples have RSS values that are similar to the jamming attack samples, leading the model to classify them as anomalies.
This is most likely because of how the dataset has been created, as the normal traffic samples were measured in a real-world scenario where the RSS values would be effected by external noise. 

Instead of a impairment, we see this an improvement opportunity. The fact that the dataset contains noise means it is more representative of a real-world scenario, where the drone might be moving trough different environments and thus be subject to environmental noise.

\subsubsection{Majority rule model testing} \label{sec:majorityRuleModelTesting}

Having understood the nature of the problem, we decided to implement a majority rule system to reduce the number of false positives. The improved model would use the Tuned Isolation Forest model's results and then pass them to a Majority Rule module, as shown in Figure \ref{fig:MajorityRuleDiagram}. 

\begin{figure}[H]
	\includegraphics[width=12.5 cm]{img/ModulesStructure.jpg}
	\caption{Majority Rule system diagram. The Tuned Isolation Forest model results are passed to the Majority Rule module, that then provides the final classification.}
	\label{fig:MajorityRuleDiagram}
	\end{figure}   
\unskip

The logic behind the Majority Rule module is simple. The Majority Rule takes as input the classification results of the IF model and inserts them into a sliding window. If the datapoint is classified by the Tuned IF as an anomaly, the Majority Rule module checks the contents of the sliding window. If the 
majority of the datapoints in the window are classified as anomalies, the data point is classified as an anomaly. If the majority of the datapoints in the window are classified as normal, the data point is classified as normal (see code snipped \ref{alg:majority_rule}).

\begin{algorithm}
	\caption{Majority Rule Algorithm}\label{alg:majority_rule}
	\begin{algorithmic}[1]
		\State \hspace{1em} $\text{window} \leftarrow []$
		
		\For{each index in range(len(classification))}
			\If{length of window equals predefined window size}
				\State \hspace{1em} $\text{window.pop}(0)$
			\EndIf
			
			\State \hspace{1em} $\text{window.append}(\text{classification}[index])$
			
			\If{current classification is OUTLIER and the count of OUTLIERS in the window 
		 \State is less than or equal to half the window size}
				\State \hspace{1em} $\text{classification}[index] \leftarrow \text{INLIERS}$
			\EndIf
		\EndFor
		
		\State \hspace{1em} $\text{return classification}$
	\end{algorithmic}
\end{algorithm}

To determine the optimal value for the \textit{window\_size} parameter, we test the model in the same way as in the hyperparameters tuning phase. The model parameters were set to the best performing values from the tuning phase (table \ref{tab:best_hyperparameters}). Table \ref{tab:window_size_tuning} shows the tuning values for the \textit{window\_size} parameter.

\begin{table}[H]
	\caption{window\_size tuning values.}\label{tab:window_size_tuning}
	\begin{tabularx}{\textwidth}{CC}
	\toprule
	\textbf{window\_size} & \textbf{Values} \\
	\midrule
	Minimum & 1 \\
	Maximum & 100 \\
	Step & 1 \\
	\bottomrule
\end{tabularx}
\end{table}

From Figure \ref{fig:window_size_tuning} we can see that the \textit{window\_size} parameter has a considerable impact on the model performance. The optimal value for the \textit{window\_size} parameter was found to be \textbf{window\_size = 39}.

\begin{figure}[H]
	\includegraphics[width=10.5cm]{img/WindowSizeTuning.png}
	\caption{window\_size tuning results.}\label{fig:window_size_tuning}
\end{figure}

After defining the value for the \textit{window\_size} parameter, we tested the model against the same input signal used for the standard tuned model (Figure\ref{fig:InputSignal}). The results of the model classification are shown in Figure \ref{fig:majorityRuleIsolationResults}. 

\begin{figure}[H]
	\begin{adjustwidth}{-\extralength}{0cm}
	\centering
	\includegraphics[width=21cm]{img/MajorityRuleIsolatioForestClassification.png}
	\caption{Classification results from the Majority Rule Isolation Forest model}\label{fig:majorityRuleIsolationResults}
	\end{adjustwidth}
\end{figure}

In Tables \ref{tab:majority_rule_confusionMatrix} and \ref{tab:majority_rule_performanceMetrics} we can see a comparison between the tuned model and the Majority Rule model.

\begin{table}[H]
    \caption{Confusion Matrix Components Comparison.}\label{tab:majority_rule_confusionMatrix}
    \begin{tabularx}{\textwidth}{CCC}
    \toprule
    \textbf{Metric} & \textbf{Tuned Isolation Forest} & \textbf{Majority Rule Isolation Forest} \\
    \midrule
    \textbf{TP}  & 1997  & 1982 \\
    \textbf{FN}  & 3     & 18   \\
    \textbf{FP}  & 1565  & 27   \\
    \textbf{TN}  & 18435 & 19973 \\
    \bottomrule
    \end{tabularx}
\end{table}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/ConfusionMatrixTunedIF.png}
		\caption{}
		\label{fig:ConfusionMatrixStandardTunedIF1}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/ConfusionMatrixMajorityIF.png}
		\caption{}
		\label{fig:ConfusionMatrixMajorityIF}
	\end{subfigure}
	\caption{Confusion Matrix for the tuned Isolation Forest model \textbf{(a)} and the Majority Rule Isolation Forest model \textbf{(b)}.}
	\label{fig:ConfusionMatrixTunedMajorityIF}
\end{figure}

\begin{table}[H]
    \caption{Performance Metrics Comparison.}\label{tab:majority_rule_performanceMetrics}
    \begin{tabularx}{\textwidth}{CCC}
    \toprule
    \textbf{Metric} & \textbf{Tuned Isolation Forest} & \textbf{Majority Rule Isolation Forest} \\
    \midrule
    \textbf{Accuracy}  & 0.929 & 0.998 \\
    \textbf{Precision} & 0.561 & 0.987 \\
    \textbf{Recall}    & 0.999 & 0.991 \\
    \textbf{F1 Score}  & 0.718 & 0.989 \\
    \bottomrule
    \end{tabularx}
\end{table}

The results show that the Majority Rule Model is effective in mitigating the high number of false positives that were present in the first version of the model. 
Given the resource constrained nature of the scenario, we decided to test the computational impact of the Majority Rule module against the standard tuned model. 
Classification times and training times were measured for both models and the results are shown in Figures \ref{fig:majority_rule_classification_time} and \ref{fig:majority_rule_training_time}.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/classificationTimeComparison.png}
		\caption{Classification time comparison.}
		\label{fig:majority_rule_classification_time}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/trainingTimeComparison.png}
		\caption{Training time comparison.}
		\label{fig:majority_rule_training_time}
	\end{subfigure}
	\caption{Comparison of the standard tuned model and the Majority Rule model training and classification times.}
	\label{fig:majority_rule_time_comparison}
\end{figure}

Graph \ref{fig:majority_rule_classification_time} shows that there is indeed a difference in classification time, with the standard model being faster. This is due to the additional computational complexity added by the Majority Rule module, which requires updating and checking of the sliding window for each classified datapoint. 
Figure \ref{fig:majority_rule_training_time} on the other hand shows that, as expected, training time is not affected by the Majority Rule module.

\subsubsection{Comparison against existing solution}\label{sec:comparisonAgainstExistingSolution}

As mentioned in Section \ref{sec:DatasetChoice}, this work is based on the work of \cite{JammingDetectionIoT-Hussain}, where the authors proposed a solution for jamming attack detection based on CNNs. In their paper, one of the drawbacks that the authors cite with their solution is the low detection rate against periodic jamming, as well as a non reliable classification of normal traffic. 
We decided to compare our solution against the solution of the authors of the dataset we used. 
The results show two significant Figures as the results provided in the compared paper were in this format. Results in the case of constant jamming were very similar, with both models scoring $1.0$ in all the metrics.
Table \ref{tab:periodic_jamming_comparison} shows the comparison between the two models in the case of periodic jamming and Table \ref{tab:normal_traffic_comparison} shows the comparison between the two models in classification of normal traffic.


\begin{table}[H]
	\caption{Comparison between the proposed approach and the approach of \cite{JammingDetectionIoT-Hussain} in the case of periodic jamming.}\label{tab:periodic_jamming_comparison}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CCC}
	\toprule
	\textbf{Metric} & \textbf{Proposed Approach} & \textbf{CNN Approach} \\
	\midrule
	\textbf{Accuracy}  & 0.98 & N.D \\
	\textbf{Precision} & 0.99 & 0.73 \\
	\textbf{Recall}    & 0.95 & 0.83 \\
	\textbf{F1 Score}  & 0.97 & 0.78 \\
	\bottomrule
	\end{tabularx}
\end{table}

\begin{table}[H]
	\caption{Comparison between the proposed approach and the approach of \cite{JammingDetectionIoT-Hussain} in the case of normal traffic classification.}\label{tab:normal_traffic_comparison}
	\newcolumntype{C}{>{\centering\arraybackslash}X}
	\begin{tabularx}{\textwidth}{CCC}
	\toprule
	\textbf{Metric} & \textbf{Proposed Approach} & \textbf{CNN Approach} \\
	\midrule
	\textbf{Accuracy}  & 1.00 & N.D \\
	\textbf{Precision} & 1.00 & 0.80 \\
	\textbf{Recall}    & 1.00 & 0.70 \\
	\textbf{F1 Score}  & 1.00 & 0.75 \\
	\bottomrule
	\end{tabularx}
\end{table}

In Figures \ref{fig:periodicJammingClassification} and \ref{fig:normalTrafficClassification} we can see the classification results of our proposed solution in the case of a testing sample size of $10000$ samples.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/OnlyPeriodicJamming.png}
		\caption{Periodic Jamming classification.}
		\label{fig:periodicJammingClassification}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{img/OnlyNormalTraffic.png}
		\caption{Normal Traffic classification.}
		\label{fig:normalTrafficClassification}
	\end{subfigure}
	\caption{Classification results of the proposed solution.}
	\label{fig:proposedSolutionClassification}
\end{figure}

Our solution is able to achieve considerably better results in the classification of normal traffic and periodic jamming, while maintaining the same level of performance in the case of constant jamming.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}


In this article we analyzed wether it was possible to employ an Isolation Forest model to detect jamming attacks in a 6G drone scenario. We tuned the hyperparameters of the model and tested it against the default Isolation Forest model. 
We achieved a considerable improvement in performance thanks to the tuning process (section \ref{sec:standardModelTesting}), but despite the high recall and accuracy scores, the model suffered too much from a high number of false positives, caused by the inherent noise of the dataset. 
To mitigate this issue, we proposed the integration of the Isolation Forest model with a Majority Rule module (section \ref{sec:majorityRuleModelTesting}). The \textit{window\_size} parameter of the Majority Rule module was tuned to provide the best performance.
The addition of the Majority Rule module proved extremely effective in reducing the number of false positives, greatly improving the model's precision. 

Integration of the Majority Rule module also impacted total classification time as shown in Figure \ref{fig:majority_rule_classification_time}, but the linear trend \cite{IsolationForestLiu} that we expected from the isolation forest model was preserved, meaning that the classification time complexity was kept at $O(n)$. 
In our opinion the trade-off between the increased classification time and the improved performance is worth it, as the model is now much more reliable in a real-world scenario, where noise from the surrounding environment is almost always present.
The linear time complexity of the classification and low memory usage make the proposed solution suitable for a resource constrained environment such as the analyzed 6G drone scenario.

As shown in Section \ref{sec:comparisonAgainstExistingSolution}, the proposed solution outperformed the solution proposed by \cite{JammingDetectionIoT-Hussain} in both the detection of periodic jamming and the classification of normal traffic, while achieving the same performance against constant jamming attacks. 
We believe that the importance of correct classification of normal traffic is often underestimated, as a high number of false positives can lead to the activation of resource intensive countermeasures, even at times when they are not needed. 

\section{Conclusions}

In this article we analyzed the use of the Isolation Forest unsupervised machine learning algorithm for the detection of jamming attacks. We compared the performance of the base Isolation Forest model against a version specifically tuned to detect jamming attacks. In the tuning phase, we paid particular attention to the computational added by each parameter and tried to find the balance between performance and efficiency. 
We then proposed the integration of a Majority Rule module to reduce the number of false positives caused by the inherent noise of the dataset. The Majority Rule module was tuned to provide the best performance and proved effective in mitigating the problem of false positives, while still maintaining a linear complexity in classification time.
We tested the model against a dataset that included normal traffic, constant jamming, and periodic jamming attacks, with an unbalanced number of normal traffic samples and jamming attack samples to better reflect a real-world scenario.
We compared the performance of the proposed solution against the solution proposed by \cite{JammingDetectionIoT-Hussain} and found that our solution outperformed the existing solution in both the detection of periodic jamming and the classification of normal traffic, while retaining the same performance against constant jamming attacks.


In a real world scenario, a 6G drone integrating the proposed solution would periodically run the tuning phase of the algorithm, selecting the best hyperparameters for the current environment. This could happen periodically or whenever there is a change in the environment caused by the drone moving to a different location. 
After tuning of the model, the drone would periodically sample incoming signals and classify them using the Majority Rule module. If the model detects a jamming attack, the drone could activate built in countermeasures like frequency hopping or DSSS to mitigate the effects of the attack. 

Future research could test the model against a wider range of jamming attacks types, as well as analyze the impact of real world noise on the model performance.
Mounting the model on an actual drone would be the best way to achieve a real-world test and would provide valuable insights into how to further improve its performance.

As discussed in Section \ref{sec:DetectionMitigation} devices integrated into 6G networks are expected to have a higher degree of sensing capabilities compared to current devices \cite{6GRoadmapLetaief}. Thanks to the properties of the Isolation Forest to work on high dimensional data, the model could be easily expanded to include more classification features, such as the RSV metric proposed in \cite{JammingDetectionIoT-Hussain}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Patents}

%This Section is not mandatory, but may be added if there are patents resulting from the work reported in this manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{Conceptualization, Francesco Chiti and Sergio Cibecchini; methodology, Sergio Cibecchini; software, Sergio Cibecchini; validation, Francesco Chiti and Laura Pierucci; formal analysis, Sergio Cibecchini; investigation, Sergio Cibecchini; resources, Francesco Chiti and Laura Pierucci; data curation, Sergio Cibecchini; writing‚Äîoriginal draft preparation, Sergio Cibecchini; writing‚Äîreview and editing, Francesco Chiti and Laura Pierucci; visualization, Sergio Cibecchini; supervision, Francesco Chiti and Laura Pierucci. All authors have read and agreed to the published version of the manuscript.}

\funding{This research received no external funding.}

%\institutionalreview{In this section, you should add the Institutional Review Board Statement and approval number, if relevant to your study. You might choose to exclude this statement if the study did not require ethical approval. Please note that the Editorial Office might ask you for further information. Please add ‚ÄúThe study was conducted in accordance with the Declaration of Helsinki, and approved by the Institutional Review Board (or Ethics Committee) of NAME OF INSTITUTE (protocol code XXX and date of approval).‚Äù for studies involving humans. OR ‚ÄúThe animal study protocol was approved by the Institutional Review Board (or Ethics Committee) of NAME OF INSTITUTE (protocol code XXX and date of approval).‚Äù for studies involving animals. OR ‚ÄúEthical review and approval were waived for this study due to REASON (please provide a detailed justification).‚Äù OR ‚ÄúNot applicable‚Äù for studies not involving humans or animals.}

%\informedconsent{Any research article describing a study involving humans should contain this statement. Please add ``Informed consent was obtained from all subjects involved in the study.'' OR ``Patient consent was waived due to REASON (please provide a detailed justification).'' OR ``Not applicable'' for studies not involving humans. You might also choose to exclude this statement if the study did not involve humans.

%Written informed consent for publication must be obtained from participating patients who can be identified (including by the patients themselves). Please state ``Written informed consent has been obtained from the patient(s) to publish this paper'' if applicable.}

\dataavailability{The dataset used in this study is openly available and provided by the authors of \cite{JammingDetectionIoT-Hussain} at the following URL: \url{https://github.com/AMHD/Jamming-Detection-in-IoT-Wireless-Networks-An-Edge-AI-Based-Approach}. The code for the tests and the jamming detection model developed in this study is available in the following repository: \url{https://github.com/cibecs/JammingAttacksAnomalyDetection.git}.}

\acknowledgments{This work was partially supported by the European Union under the Italian National Recovery and Resilience Plan (NRRP) of NextGenerationEU, in partnership with the project ‚ÄúTelecommunications of the Future‚Äù (PE00000001‚Äîprogram ‚ÄúRESTART‚Äù). Additionally, this article publication is based upon work from COST Action CA22168 for "Physical Layer Security for Trustworthy and Resilient 6G Systems (6G-PHYSEC)," supported by COST (European Cooperation in Science and Technology).}

\conflictsofinterest{The authors declare no conflicts of interest.} 

\abbreviations{Abbreviations}{
The following abbreviations are used in this manuscript:\\

\noindent 
\begin{tabular}{@{}ll}
SDN & Software Defined Networks\\
UAVs & Unmanned Aerial Vehicles \\
3GPP & 3rd Generation Partnership Project \\
ML & Machine Learning \\
V2X & Vehicle to Everything \\
FPV & First Person View \\
DOS & Denial Of Service \\
SNR & Signal to Noise Ratio \\
RSSI & Received Signal Strength Indicator \\
PDR & Packet Delivery Ratio \\
CIA & Confidentiality, Integrity, Availability \\
IoT & Internet of Things \\
AI & Artificial Intelligence \\
DSSS & Direct Sequence Spread Spectrum \\
FHSS & Frequency Hopping Spread Spectrum \\
OSI & Open Systems Interconnection \\
dBm & Decibel-milliwatts \\
IF & Isolation Forest \\
CNN & Convolutional Neural Network \\
RSV & Relative Speed Variation \\


\end{tabular}
}


\begin{adjustwidth}{-\extralength}{0cm}
%\printendnotes[custom] % Un-comment to print a list of endnotes

\reftitle{References}

%=====================================
% References, variant B: internal bibliography
%=====================================
\begin{thebibliography}{999}

\bibitem[Taylor(2024)]{5GStatisticsTaylor}
5G - statistics \& facts. Available online: \url{https://www.statista.com/topics/3447/5g/topicOverview} (accessed on 13 September 2024).

\bibitem[Letaief et al.(2019)]{6GRoadmapLetaief}
Letaief, K.B.; Chen, W.; Shi, Y.; Zhang, J.; AI, B. The Roadmap to 6G: AI Empowered Wireless Networks. {\em IEEE Communications Magazine} {\bf 2019}, {\em 57}, 84--90. \url{https://doi.org/10.1109/MCOM.2019.1900271}.

\bibitem[EuropeanCommission(2024)]{DronesEC}
Unmanned aircraft (drones). Available online: \url{https://transport.ec.europa.eu/transport-modes/air/aviation-safety/unmanned-aircraft-drones_en} (accessed on 13 September 2024).

\bibitem[Laricchia(2024)]{DronesStatisticsLaricchia}
Laricchia, F. Consumer and commercial drones - statistics and facts. Available online: \url{https://www.statista.com/topics/7939/drones/\#topicOverview} (accessed on 13 September 2024).

\bibitem[Sultan(2018)]{5GV2XSultan}
Sultan, A. Study on enhancement of 3GPP support for 5G V2X services. Tech. Rep. {\em 3GPP}, 2018.

\bibitem[Hassija et al.(2021)]{DroneCommHassija}
Hassija, V.; Kumar, R.; Gupta, H.; Singh, S.; Sharma, P. Fast, Reliable, and Secure Drone Communication: A Comprehensive Survey. {\em IEEE Communications Surveys and Tutorials} {\bf 2021}, {\em 23}, 2802--2832. \url{https://doi.org/10.1109/COMST.2021.3097916}.

\bibitem[Cawthra(2020)]{DataIntegrityCawthra}
Cawthra, J. Data Integrity: Detecting and Responding to Ransomware and Other Destructive Events. {\em NIST Special Publication} {\bf 2020}, {\em 1800-26A}.

\bibitem[Lyamin et al.(2018)]{VANETsAI-Lyamin}
Lyamin, N.; Samuylov, A.; Gaidamaka, Y.; Vinel, A.; Koucheryavy, Y. AI-Based Malicious Network Traffic Detection in VANETs. {\em IEEE Network} {\bf 2018}, {\em 32}, 15--21. \url{https://doi.org/10.1109/MNET.2018.1800074}.

\bibitem[Boualouache and Engel(2023)]{MLMisbehavior5GBoualouache}
Boualouache, A.; Engel, T. A Survey on Machine Learning-Based Misbehavior Detection Systems for 5G and Beyond Vehicular Networks. {\em IEEE Communications Surveys and Tutorials} {\bf 2023}, {\em 25}, 1128--1172. \url{https://doi.org/10.1109/COMST.2023.3236448}.

\bibitem[Feng and Haykin(2019)]{AntiJammingV2V-Feng}
Feng, S.; Haykin, S. Cognitive Risk Control for Anti-Jamming V2V Communications in Autonomous Vehicle Networks. {\em IEEE Transactions on Vehicular Technology} {\bf 2019}, {\em 68}, 9920--9934. \url{https://doi.org/10.1109/TVT.2019.2935999}.

\bibitem[Owano(2024)]{RQ170DroneOwano}
Owano, N. RQ-170 drone's ambush facts spilled by Iranian engineer. Available online: \url{https://phys.org/news/2011-12-rq-drone-ambush-facts-iranian.html} (accessed on 14 September 2024).

\bibitem[Gross and TOI Staff(2024)]{IranianUAVGross}
Gross, J.A.; TOI Staff. Iranian UAV that entered Israeli airspace seems to be American stealth knock-off. Available online: \url{https://www.timesofisrael.com/iranian-uav-that-enteredisraeli-airspace-seems-to-be-american-stealth-knock-off} (accessed on 16 May 2024).

\bibitem[Chorti et al.(2022)]{6GSecurity-Chorti}
Chorti, A.; Hollanti, C.; Koorapaty, H.; Poor, H.V. Context-Aware Security for 6G Wireless: The Role of Physical Layer Security. {\em IEEE Communications Standards Magazine} {\bf 2022}, {\em 6}, 102--108. https://doi.org/10.1109/MCOMSTD.0001.2000082.

\bibitem[Sciancalepore et al.(2023)]{JammingDetection-Sciancalepore}
Sciancalepore, S.; Kusters, F.; Abdelhadi, N.K.; Oligeri, G. Jamming Detection in Low-BER Mobile Indoor Scenarios via Deep Learning. {\em arXiv} {\bf 2023}, eprint: 2306.10912. Available online: \url{https://arxiv.org/abs/2306.10912}.

\bibitem[Boualouache and Engel(2023)]{MLMisbehavior5GBoualouache}
Boualouache, A.; Engel, T. A Survey on Machine Learning-Based Misbehavior Detection Systems for 5G and Beyond Vehicular Networks. {\em IEEE Communications Surveys and Tutorials} {\bf 2023}, {\em 25}, 1128--1172. https://doi.org/10.1109/COMST.2023.3236448.

\bibitem[Hussain et al.(2023)]{JammingDetectionIoT-Hussain}
Hussain, A.; Zhang, M.; Bhatia, S.; Cheng, L. Jamming Detection in IoT Wireless Networks: An Edge-AI Based Approach. In Proceedings of the 12th International Conference on the Internet of Things, IoT ‚Äô22; Association for Computing Machinery: Delft, Netherlands, 2023; pp. 57--64. ISBN: 9781450396653. https://doi.org/10.1145/3567445.3567456.

\bibitem[Sobot(2012)]{WirelessCommSobot}
Sobot, R. \textit{Wireless Communication Electronics: Introduction to RF Circuits and Design}; Springer: 2012; p. 252. ISBN 9783030486303.

\bibitem[Liu et al.(2008)]{IsolationForestLiu}
Liu, F.T.; Ting, K.M.; Zhou, Z.-H. Isolation Forest. In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, Pisa, Italy, 2008; pp. 413--422. https://doi.org/10.1109/ICDM.2008.17.

\bibitem[Scikit-learn(2024)]{IsolationForestScikitLearn}
Scikit-learn: Isolation Forest. Available online: \url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html} (accessed on 14 September 2024).

\bibitem[RaspberryPi(2024)]{RaspberryPi3ModelB}
Raspberry Pi 3 Model B. Available online: \url{https://www.raspberrypi.com/products/raspberry-pi-3-model-b/} (accessed on 14 September 2024).

\bibitem[Karagiannis and Argyriou(2018)]{JammingDetection-Karagiannis}
Karagiannis, D.; Argyriou, A. Jamming attack detection in a pair of RF communicating vehicles using unsupervised machine learning. {\em Vehicular Communications} {\bf 2018}, {\em 13}, 56--63. https://doi.org/10.1016/j.vehcom.2018.05.001. Available online: \url{https://www.sciencedirect.com/science/article/pii/S221420961730222X}.

\bibitem[Hong et al.(2023)]{HybridJammingDetection-Hong}
Hong, S.; Kim, K.; Lee, S.-H. A Hybrid Jamming Detection Algorithm for Wireless Communications: Simultaneous Classification of Known Attacks and Detection of Unknown Attacks. {\em IEEE Communications Letters} {\bf 2023}, {\em 27}, 1769--1773. https://doi.org/10.1109/LCOMM.2023.3275694.

\bibitem[Zuo et al.(2021)]{GPSSpoofingDetection-Zuo}
Zuo, S.; Liu, Y.; Zhang, D.; Xin, P.; Liu, T. Detection of GPS Spoofing Attacks Based on Isolation Forest. In Proceedings of the 2021 IEEE 9th International Conference on Information, Communication and Networks (ICICN), Xi'an, China, 2021; pp. 357--361. https://doi.org/10.1109/ICICN52636.2021.9673863.


\end{thebibliography}

% If authors have biography, please use the format below
%\section*{Short Biography of Authors}
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author1.pdf}}}
%{\textbf{Firstname Lastname} Biography of first author}
%
%\bio
%{\raisebox{-0.35cm}{\includegraphics[width=3.5cm,height=5.3cm,clip,keepaspectratio]{Definitions/author2.jpg}}}
%{\textbf{Firstname Lastname} Biography of second author}

% For the MDPI journals use author-date citation, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)


\PublishersNote{}
\end{adjustwidth}
\end{document}

